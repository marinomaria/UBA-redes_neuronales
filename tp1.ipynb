{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uh0IJK1M9zHr"
      },
      "source": [
        "# **Redes Neuronales Artificiales**: Trabajo Práctico 1\n",
        "\n",
        "#### Integrantes:\n",
        "\n",
        "- Maximiliano Dacko, LU  284/21\n",
        "- María Marino, LU 450/21\n",
        "- Giovanni Marraffini, LU 292/21"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RTv4jpg5_UdK"
      },
      "source": [
        "## Clase `MLP`: Multi Level Perceptron"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eJxl6z1FTPG"
      },
      "source": [
        "En primer lugar, se crea una clase para facilitar las acciones más utilizadas por la red neuronal. Esta consta de un constructor donde se definen la cantidad de neuronas de cada capa y la función de activación. Asimismo se crean las matrices pseudoaleatorias con una distribución normal.\n",
        "\n",
        "Además, se utilizan como métodos públicos una función de activación de la red, una función de corrección de los pesos que utiliza el algortimo de *backpropagation* del error y una función para obtener los valores de salida dados nuevos datos de entrada.\n",
        "\n",
        "Se decidió utilizar la misma función de activación para todas las capas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WtWGriXIPiva"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, sizes: list[int], batchSize: int, f: str = 'tanh'):\n",
        "        self.S = sizes\n",
        "        self.L = len(self.S)\n",
        "        self.N = batchSize\n",
        "        self.Y = [np.empty(shape=(self.N, self.S[i - 1] + 1)) for i in range(self.L)]\n",
        "        self.W = [None] + [np.random.normal(0, 0.5, (self.S[i - 1] + 1, self.S[i])) for i in range(1, self.L)]\n",
        "        self._f = f\n",
        "\n",
        "    \n",
        "    def _add_bias(self, V):\n",
        "        bias = np.ones((len(V),1))\n",
        "        return np.hstack([V, bias])\n",
        "\n",
        "    def _sub_bias(self, V):\n",
        "        return V[:, :-1]\n",
        "    \n",
        "    @property\n",
        "    def f(self):\n",
        "        return self._f\n",
        "\n",
        "    @f.setter\n",
        "    def f(self, fun):\n",
        "        if fun != 'tanh' and fun != 'sigmoid': \n",
        "            raise Exception('Activation function should be  \\'tanh\\' or \\'sigmoid\\'')\n",
        "    \n",
        "    def activation(self, Xh):\n",
        "        self.Y = [np.empty(shape=(self.N, self.S[i - 1] + 1)) for i in range(self.L)]\n",
        "        Y_b = Xh\n",
        "        for k in range(1, self.L):\n",
        "            self.Y[k - 1] = self._add_bias(Y_b)\n",
        "            if self.f == 'sigmoid':\n",
        "                Y_b = sigmoid(self.Y[k - 1] @ self.W[k])\n",
        "            else:\n",
        "                Y_b = np.tanh(self.Y[k - 1] @ self.W[k])\n",
        "        self.Y[self.L - 1] = Y_b\n",
        "        return self.Y\n",
        "    \n",
        "    def correction(self, Yh, Zh):\n",
        "        D = [np.empty(shape=(self.N, self.S[i - 1] + 1)) for i in range(self.L)]\n",
        "        deltaW = [None] + [np.empty(shape=(self.S[i - 1] + 1, self.S[i])) for i in range(1, self.L)]\n",
        "        E = Zh - Yh[self.L - 1]\n",
        "        if self.f == 'sigmoid':\n",
        "            dY = Yh[self.L - 1] * (1 - Yh[self.L - 1]) # Derivative of sigmoid\n",
        "        else:\n",
        "            dY = 1 - np.square(Yh[self.L - 1]) # Derivative of tanh\n",
        "        D[self.L - 1] = E * dY\n",
        "        for k in reversed(range(1, self.L)):\n",
        "            deltaW[k] = Yh[k - 1].T @ D[k]\n",
        "            E = D[k] @ self.W[k].T\n",
        "            if self.f == 'sigmoid':\n",
        "                dY = Yh[k - 1] * (1 - Yh[k - 1]) # Derivative of sigmoid\n",
        "            else:\n",
        "                dY = 1 - np.square(Yh[k - 1]) # Derivative of tanh\n",
        "            D[k - 1] = self._sub_bias(E * dY)\n",
        "        return deltaW\n",
        "\n",
        "    def predict(self, x):\n",
        "      return self.activation(x)[-1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a65siJFgTxiE"
      },
      "source": [
        "## **Ejercicio 1**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVE0m4wQFEG"
      },
      "source": [
        "Se subieron los datos a un repositorio público para facilitar su importación.\n",
        "\n",
        "Por el enunciado, sabemos que el conjunto de datos consta de las siguientes columnas:\n",
        "1. *Diagnóstico, dónde 1 = maligno y 0 = benigno*. (**Nuestra variable objetivo**).\n",
        "2. *Radio: media de la distancia desde el centro a los puntos deperímetro*\n",
        "3. *Textura: desviación estándar de los valores en escala de gris*\n",
        "4. *Perímetro*\n",
        "5. *Área*\n",
        "6. *Suavidad: variaciones locales en la longitud del radio*\n",
        "7. *Compacidad: perímetro^2 / área - 1*\n",
        "8. *Concavidad: severidad de las porciones cóncavas del contorno*\n",
        "9. *Puntos cóncavos: proporción de porciones cóncavas del contorno*\n",
        "10. *Simetría*\n",
        "11. *Dimensión fractal*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lH9SwGEzRzFv"
      },
      "outputs": [],
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/marinomaria/UBA-redes_neuronales/main/dataset/tp1-ej1.txt', delimiter = ',')\n",
        "\n",
        "datasetSize = data.shape[0]\n",
        "\n",
        "inputSize = 10\n",
        "outputSize = 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aTRuPwKqRTHK"
      },
      "source": [
        "Se decide separar el 10% de los datos para luego evaluar con estos al final del entrenamiento y obtener un estimado del error real que podría llegar a cometer el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgvFggGEgBc2",
        "outputId": "d2f17ea4-6193-4a2d-c82c-b6d83afcec5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((369, 11), (41, 11))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.shuffle(data)\n",
        "\n",
        "evalSetSize = int(datasetSize * 0.1)\n",
        "trainSet = data[: - evalSetSize, :]\n",
        "evalSet = data[- evalSetSize:, :]\n",
        "\n",
        "trainSet.shape, evalSet.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1-iafbtNaHAJ"
      },
      "source": [
        "### Estandarización"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TprcqetEAwIS"
      },
      "source": [
        "Para cada variable miramos su rango y promedio, y luego procedemos a estandarizar todo el dataset de entrenamiento **sin** la variable objetivo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRB7oMdqBDvl",
        "outputId": "ecf15c89-e007-4623-869f-6256688a5615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna 0: \n",
            " Rango: 0.0 - 1.0 \n",
            " Promedio: 0.4796747967479675\n",
            "Columna 1: \n",
            " Rango: 6.981 - 28.11 \n",
            " Promedio: 18.55281842818428\n",
            "Columna 2: \n",
            " Rango: 10.034 - 33.81 \n",
            " Promedio: 21.26975609756098\n",
            "Columna 3: \n",
            " Rango: 43.79 - 188.5 \n",
            " Promedio: 113.85478861788619\n",
            "Columna 4: \n",
            " Rango: 143.5 - 2501.0 \n",
            " Promedio: 844.3650433604336\n",
            "Columna 5: \n",
            " Rango: 0.053 - 4.163 \n",
            " Promedio: 1.790352303523035\n",
            "Columna 6: \n",
            " Rango: 0.387 - 3.345 \n",
            " Promedio: 1.8854715447154473\n",
            "Columna 7: \n",
            " Rango: 0.427 - 7.283 \n",
            " Promedio: 3.6615067750677506\n",
            "Columna 8: \n",
            " Rango: 0.201 - 9.013 \n",
            " Promedio: 4.548010840108401\n",
            "Columna 9: \n",
            " Rango: 0.106 - 1.304 \n",
            " Promedio: 0.728018970189702\n",
            "Columna 10: \n",
            " Rango: 0.094 - 2.974 \n",
            " Promedio: 1.5555880758807588\n"
          ]
        }
      ],
      "source": [
        "for j in range(trainSet.shape[1]):\n",
        "  print(f'Columna {j}: \\n Rango: {trainSet[:, j].min()} - {trainSet[:, j].max()} \\n Promedio: {trainSet[:, j].mean()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL3PdKypUsBH",
        "outputId": "c8df3201-4fb0-43b2-fc55-2d1e914ff0ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((369, 1), (369, 10))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = trainSet[:, 0].reshape(trainSet.shape[0], 1)\n",
        "x = trainSet[:, 1:trainSet.shape[1]]\n",
        "\n",
        "z.shape, x.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ij3LqZ9nGA29"
      },
      "source": [
        "La estandarización utilizada es:\n",
        "\n",
        "$z = \\dfrac{x - \\mu}{\\sigma}$\n",
        "\n",
        "donde $x$ es el valor original, $\\mu$ y $\\sigma$ son respectivamente la media y la desviación estándar de la variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UAeQFcJ4bTno"
      },
      "outputs": [],
      "source": [
        "x = (x - x.mean(0)) / x.std(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sutyEabMglU8"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gNA-WMvcG6S5"
      },
      "source": [
        "Definimos el *batch size* (tamaño del lote) como un 10% del total de nuestro dataset. Teniendo en cuenta que ya quitamos un 10% para validación, nos quedan 9 lotes para entrenamiento.\n",
        "\n",
        "Asimismo inicializamos una instancia de la clase `MLP`, definiendo aquí parte de su arquitectura. En este caso, nuestra red neuronal tendrá una única capa oculta cuyo tamaño será el doble del tamaño de entrada, y todas las capas utilizarán la función sigmoide como función de activación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wz7ycCxVUmiI"
      },
      "outputs": [],
      "source": [
        "bSize = int(datasetSize * 0.1)\n",
        "M = MLP([inputSize, inputSize * 2, outputSize], bSize, 'sigmoid')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhg9yQnZJCUk"
      },
      "source": [
        "Entrenamos el modelo de a lotes. \n",
        "\n",
        "Cada ciclo del `while loop` exterior representa una época (*epoch*) y en él permutamos el orden de los datos para intentar evitar estancarnos en un mínimo local de nuestra función de error.\n",
        "\n",
        "En cada iteración del `for loop` ingresamos un lote al modelo, activando la red y luego corrigiendo sus pesos con los métodos ya mencionados de la clase `MLP`.\n",
        "\n",
        "Para calcular el error, sumamos el cuadrado de la diferencia entre el valor esperado (variable objetivo) y el valor predicho por el modelo, y luego dividimos por la cantidad de términos de la suma (error cuadrático medio).\n",
        "\n",
        "Por último, imprimimos para algunas épocas el error estimado para poder observar su evolución."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddVTnDwob6IJ",
        "outputId": "fd8bed90-cf50-4ebb-f7ce-2c45184278e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 error: 11.309736414143662\n",
            "epoch: 10000 error: 2.835541017156794\n",
            "epoch: 20000 error: 0.5508116212977473\n",
            "epoch: 30000 error: 0.22391331909331255\n",
            "epoch: 39999 error: 0.12583386340479386\n"
          ]
        }
      ],
      "source": [
        "minError = 0.001\n",
        "maxEpoch = 40000\n",
        "e = 1.0\n",
        "eta = 0.001\n",
        "epoch = 0\n",
        "p = x.shape[0]\n",
        "\n",
        "while e > minError and epoch < maxEpoch:\n",
        "    stochastic = np.random.permutation(p)\n",
        "    e = 0.0\n",
        "    for i in range(0, p, bSize):\n",
        "        batch = stochastic[i : i + bSize]\n",
        "        xi = x[batch].reshape(bSize, 10)\n",
        "        zi = z[batch].reshape(bSize, 1)\n",
        "        yi = M.activation(xi)\n",
        "        e += np.sum(np.square(zi - yi[-1]))\n",
        "        dW = M.correction(yi, zi)\n",
        "        for j in range(1, M.L):   \n",
        "          M.W[j] += eta * dW[j]\n",
        "    e /= (p / bSize)\n",
        "    if (epoch % 10000 == 0 or epoch == 39999):\n",
        "      print(f'Epoch {epoch}, error: {e}')\n",
        "    epoch += 1 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ssUQ5dHLLH1X"
      },
      "source": [
        "### Validación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "25SPnj45LcfJ"
      },
      "source": [
        "Para validar el desempeño del modelo lo utilizamos para predecir el resultado del 10% del dataset que **no fue utilizado en su entrenamiento**.\n",
        "\n",
        "Primero estandarizamos este dataset de validación como hicimos con los datos de entrenamiento, y luego comparamos los resultados obtenidos con los esperados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2s1WDV_g33F",
        "outputId": "4e75806c-4217-4da4-caf5-ad5fbe639f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo acertó en 40 de 41 instancias (98.0 %).\n",
            "\n",
            "\n",
            "Esperado: [1.]  Predicho: [0.86864599]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.05837362]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.0023144]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.0038575]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.00422025]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.46358652]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.98712332]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.84075463]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.98283279]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.0390161]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.01116623]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.08248375]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.74606755]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.9236483]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.98304546]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.99563944]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.00041314]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.98430462]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.50206938]   Redondeado: [1.]\n",
            "Esperado: [1.]  Predicho: [0.98071656]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.48360033]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.96207196]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.07505615]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.00459792]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.96871511]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [6.15318947e-05]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.8187347]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.1117627]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.99665471]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.0105673]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.99592378]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.00621786]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.00328386]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.09428071]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.04747074]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.81679208]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.00103508]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.99916551]   Redondeado: [1.]\n",
            "Esperado: [0.]  Predicho: [0.00039893]   Redondeado: [0.]\n",
            "Esperado: [0.]  Predicho: [0.45114397]   Redondeado: [0.]\n",
            "Esperado: [1.]  Predicho: [0.99547837]   Redondeado: [1.]\n"
          ]
        }
      ],
      "source": [
        "zEval = evalSet[:, 0:1].reshape(evalSet.shape[0], 1)\n",
        "xEval = evalSet[:, 1:11]\n",
        "xEval = (xEval - xEval.mean(0)) / xEval.std(0)\n",
        "\n",
        "pred = np.zeros_like(zEval)\n",
        "\n",
        "for i in range(len(evalSet)):\n",
        "  pred[i] = M.predict(xEval[i].reshape(1, 10))\n",
        "\n",
        "print(f'El modelo acertó en {np.sum(zEval == np.round(pred))} de {len(evalSet)} instancias ({100 * np.round(np.sum(zEval == np.round(pred)) / len(evalSet), 2)} %).\\n\\n')\n",
        "\n",
        "for i in range(len(zEval)):\n",
        "  print(f'Esperado: {zEval[i]}  Predicho: {pred[i]}   Redondeado: {np.round(pred[i])}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U8jIFfISeUnw"
      },
      "source": [
        "#### Validación cruzada con *K-folds*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8snlgstqNXeQ"
      },
      "source": [
        "Por último, para tener un mayor entendimiento de la performance del modelo en el \"caso real\" utilizamos el método *K-folds*.\n",
        "\n",
        "La siguiente celda de código demora más en correr ya que entrena múltiples modelos con la misma arquitectura que el original pero variando los conjuntos de datos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7GuSlbteTSh",
        "outputId": "38f0d2ec-0b59-4567-f35c-458f3e6752b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de folds: 10. Tamaño de cada fold: 41 instancias.\n",
            "Modelo entrenado sin el fold 0. Error en la última época: 0.24977040908568715\n",
            "Modelo entrenado sin el fold 1. Error en la última época: 0.15338632601200874\n",
            "Modelo entrenado sin el fold 2. Error en la última época: 0.17776726263485912\n",
            "Modelo entrenado sin el fold 3. Error en la última época: 0.17810413681260756\n",
            "Modelo entrenado sin el fold 4. Error en la última época: 0.14886187134989365\n",
            "Modelo entrenado sin el fold 5. Error en la última época: 1.677910403886872\n",
            "Modelo entrenado sin el fold 6. Error en la última época: 0.1587617722050359\n",
            "Modelo entrenado sin el fold 7. Error en la última época: 0.16037834493560219\n",
            "Modelo entrenado sin el fold 8. Error en la última época: 0.13559293903745667\n",
            "Modelo entrenado sin el fold 9. Error en la última época: 0.15620125617833264\n"
          ]
        }
      ],
      "source": [
        "s = np.random.permutation(datasetSize)\n",
        "\n",
        "pred = np.empty(shape=(datasetSize, outputSize))\n",
        "\n",
        "print(f'Cantidad de folds: {int(datasetSize / bSize)}. Tamaño de cada fold: {bSize} instancias.')\n",
        "\n",
        "for i in range(0, datasetSize, bSize):\n",
        "    fold = s[i : i + 82]\n",
        "    evalSet = data[fold]\n",
        "    trainSet = np.delete(data, fold, 0)\n",
        "\n",
        "    x = trainSet[:, 1:11]\n",
        "    z = trainSet[:, 0]\n",
        "    \n",
        "    x = (x - x.mean(0)) / x.std(0)\n",
        "\n",
        "    M = MLP([inputSize, inputSize * 2, outputSize], bSize, 'sigmoid')\n",
        "\n",
        "    e = 1.0\n",
        "    epoch = 0\n",
        "    p = len(trainSet)\n",
        "\n",
        "    while e > minError and epoch < maxEpoch:\n",
        "        stochastic = np.random.permutation(p)\n",
        "        e = 0.0\n",
        "        for j in range(0, p, bSize):\n",
        "            batch = stochastic[j : j + bSize]\n",
        "            xj = x[batch].reshape(bSize, M.S[0])\n",
        "            zj = z[batch].reshape(bSize, M.S[-1])\n",
        "            y = M.activation(xj)\n",
        "            e += np.sum(np.square(zj - y[-1]))\n",
        "            dW = M.correction(y, zj)\n",
        "            for k in range(1, M.L):\n",
        "                M.W[k] += eta * dW[k]\n",
        "        e /= (p / bSize)\n",
        "        epoch += 1 \n",
        "\n",
        "    xEval = evalSet[:, 1:11]\n",
        "    zEval = evalSet[:, 0]\n",
        "\n",
        "    xEval = (xEval - xEval.mean(0)) / xEval.std(0)\n",
        "\n",
        "    pred[fold] = M.predict(xEval)\n",
        "    print(f'Modelo entrenado sin el fold {int(i / bSize)}. Error en la última época: {e}')\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNfKo2AoKxe"
      },
      "source": [
        "Los *K-folds* se organizan de forma tal que para cada instancia se obtiene un resultado con alguno de los $K$ modelos entrenados. Guardamos esos resultados en el arreglo `pred` y los comparamos con los valores esperados para construir las métricas de *Recall* y Precisión.\n",
        "\n",
        "$\\text{Recall} = \\dfrac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}}$\n",
        "\n",
        "$\\text{Precisión} = \\dfrac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djz3Gfn5e8Qg",
        "outputId": "9a05c0a5-5407-4085-cf80-700125b4c4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall: 0.8871794871794871\n",
            "Precisión: 0.9105263157894737\n",
            "\n",
            "\n",
            "Se cometieron 39 errores en 410 diagnósticos.\n",
            "Diagnosticamos como benignos a 22 tumores malignos.\n",
            "Diagnosticamos como malignos a 17 tumores benignos.\n"
          ]
        }
      ],
      "source": [
        "expected = data[:, 0].reshape(datasetSize, outputSize)\n",
        "\n",
        "tp = fn = tn = fp = 0\n",
        "\n",
        "for i in range(len(pred)):\n",
        "    if expected[i] == 1:\n",
        "        if np.round(pred[i]) == 1:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fn += 1\n",
        "    else:\n",
        "        if np.round(pred[i]) == 1:\n",
        "            fp += 1\n",
        "        else:\n",
        "            tn += 1\n",
        "\n",
        "print('Recall:', tp / (tp + fn))\n",
        "print('Precisión:', tp / (tp + fp))\n",
        "\n",
        "print(f'\\n\\nSe cometieron {fp + fn} errores en {datasetSize} diagnósticos.')\n",
        "print(f'Diagnosticamos como benignos a {fn} tumores malignos.')\n",
        "print(f'Diagnosticamos como malignos a {fp} tumores benignos.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C0UoMAw8r1Si"
      },
      "source": [
        "En este caso la medida principal que queremos optimizar es el *recall*, ya que al tratarse de un problema de diagnóstico de cáncer de mama es preferible sobreestimar (dar un resultado positivo para tumores benignos) que subestimar, por el impacto que puede tener en las posibilidades de tratamiento y en la calidad de vida de un paciente la detección tardía de un tumor maligno.\n",
        "\n",
        "Como alternativa para mejorar nuestro modelo podríamos agregar un *threshold* $\\epsilon$, y sólo diagnosticar como benignos aquellos casos donde el modelo devuelva resultados menores a $0,5 + \\epsilon$."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a65siJFgTxiE"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
